\section{保护隐私}
 面向隐私保护的机器学习(Privacy-Preserve Machine Learnin, PPML), 指的是使用了保护用户隐私和数据安全的防御技术的机器学习. 其中有以下几种著名方法. \citep{ppmlmancuso}
 \begin{itemize}
     \item 
 安全多方计算(Secure Multiparty Computation,  MPC)
 \item 
 供隐私保护模型训练和预测使用的 同态加密方法(Homomorphic Eneryption,  HE )
 \item 
 用于防止数据泄器的差分隐私 iferntial Piaey, DP) 方法. 
 \end{itemize}
 
 \subsection{隐私保护技术}
 \subsubsection{安全多方计算}
 安全多方计算起初是应对安全两方问题（百万富翁问题）.  
  
2.4隐私保护技术
包括三种方法, 分别是安全多方计算、同态加密和差分
本节讨论隐私保护技术, 
隐私. 
2.4.1安全多方计算
安全多方计算最初是针对一个安全两方计算问题, 即所谓的“百万富翁问题”:两个争强好胜的富翁 Alice 和 Bob 在街头相遇, 如何在不暴露各自财富的前提下比较出谁更富有？\citep{scyao1982}

被提出的, 并于1982年由姚期智提出和推广. 在安全多方计算中, 目的是协同地从每一方的隐私输人中计算函数的结果, 而不用将这些输入展示给其他方. 
\paragraph{数学描述}
有 $n $个参与者 $P_1, P_2, ...P_n$, 要以一种安全的方式共同计算一个函数, 这里的安全是指输出结果的正确性和输入信息、输出信息的保密性. 具体地讲, 每个参与者 $P_1$, 有一个自己的保密输入信息 $X_i$, $n $个参与者要共同计算一个函数 $f(X_1, X_2, ... , X_n)=(Y_1, Y_2,  ... , Y_n)$,  计算结束时, 每个参与者 $P_i $只能了解 $Y_i$,  不能了解其他方的任何信息. 

\begin{itemize}
    \item  输入隐私性：安全多方计算研究的是各参与方在协作计算时如何对各方隐私数据进行保护, 重点关注各参与方之间的隐私安全性问题, 即在安全多方计算过程中必须保证各方私密输入独立, 计算时不泄露任何本地数据. 
\item    计算正确性：多方计算参与各方就某一约定计算任务, 通过约定MPC协议进行协同计算, 计算结束后, 各方得到正确的数据反馈. 
    \item     去中心化：传统的分布式计算由中心节点协调各用户的计算进程, 收集各用户的输入信息, 而安全多方计算中, 各参与方地位平等, 不存在任何有特权的参与方或第三方, 提供一种去中心化的计算模式. 
\end{itemize}

\begin{enumerate}
    \item 参与方个数区分
    \item 计算场景区分
\end{enumerate}

主流的两方计算框架的核心是用了混淆电路（Garbled Circuit, 简称GC）和不经意传输（Oblivious Transfer）这两种密码学技术
通用的多方安全计算框架可以让多方安全地计算任何函数或某类函数的结果. 自1986年姚期智提出第一个通用的多方安全计算框架（常被称为Yao’s GC, 即姚氏加密电路）以来, 30多年间已经有BMR、GMW、BGW、SPDZ等多个多方安全计算框架陆续提出. 
\citep{GenExchsecretyao1986}
\paragraph{不经意传输:}
发送方将潜在的许多信息中的一个传递给接收方, 但是对于已传输的信息（如果有的话）则保持忽略. 


\paragraph{n取1 的不经意传输:}设A方有一个输入表 $(x_1..., x_n)$作为输入, 
B方有$i \in 1,  \dots , n$作为输入. n取1的不经意传输是一种安全多方计算协议, 其中
A不能学习到关于$i$的信息, B只能学习到$x_i$
\subsubsection{同态加密}
同态加密指对明文进行环上的加法和乘法运算再加密, 与加密后对密文进行相应的运算, 结果是等价的. 

全同态加密是指同时满足加同态和乘同态性质, 可以进行任意多次加和乘运算的加密函数. 用数学公式来表达, 即$$Dec(f(En(m_1), En(m_2), …, En(m_k)))=f(m_1, m_2, …, m_k)$$, 或写成：$$f(En(m_1), En(m_2), …, En(m_k))=En(f(m_1, m_2, …, m_k))$$, 如果f是任意函数, 称为全同态加密. 
% \cite{encrygoldwass1982}
\paragraph{加法同态}, 如果存在有效算法$\odot$$, E(x+y)=E(x)\odot E(y)$或者$ x+y=D(E(x)\odot E(y))$成立, 并且不泄漏 x 和 y. 
\paragraph{乘法同态}, 如果存在有效算法, $E(x \times y)=E(x) \dot E(y)$或者$ xy=D(E(x) E(y))$成立, 并且不泄漏 x 和 y. 



\subsubsection{差分隐私} 
差分隐私是为了允许研究者在不泄露个体信息（用户隐私）的前提下对一个数据集的整体进行分析而研究出的加密手段. \cite{DPDwork2008}
设想一个受信任的机构持有涉及众多人的敏感个人信息（例如医疗记录、观看记录或电子邮件统计）的数据集, 但想提供一个全局性的统计数据. 这样的系统被称为统计数据库. 但是, 提供有关数据的综合性统计也可能揭示一些涉及个人的信息. 事实上, 当研究人员链接两个或多个分别无害化处理的数据库来识别个人信息时, 各种公共记录匿名化的特殊方法都失效了. 而差分隐私就是为防护这类统计数据库脱匿名技术而形成的一个隐私框架. 

令 $\ varepsilon$ 为正实数, $\mathcal{A}$是将数据集作为输入的随机算法(代表持有数据的受信方的行为). 让 $\textrm{im}\mathcal{A}$表示图像的$\mathcal {A}$. 对于所有数据集$D_{1}, D_{2}$, 
算法$\mathcal{A}$ 提供 $\epsilon-$差分隐私, 在单个元素（即一个人的数据）以及$\mathcal{A}$的所有子集上有所不同 $S$. 
$$ Pr [ \mathcal{A}(D_1) \in S ] \leqslant \exp(\epsilon c) \cdot Pr [ \mathcal{A(D_2)} ] \in S  $$
其中用概率代替算法的随机性.  
  
\paragraph{劣势:}由于对于背景知识的假设过于强(在加噪音的时候需要使用与原数据分布比较类似的噪音函数, 而这一条件就限制了大多数数据其实不满足插分隐私的使用条件), 需要在查询结果中加入大量的随机化, 导致数据的可用性急剧下降. 特别对于那些复杂的查询, 有时候随机化结果几乎掩盖了真实结果. 
\paragraph{应用}
\begin{itemize}
    \item Google的RAPPOR, 用于遥测, 例如了解统计劫持用户设置的恶意软件（RAPPOR's \item open-source implementation）
    \item Google, 分享历史流量统计信息. 
    \item 2016年6月13日, 苹果公司宣布其在iOS 10中使用差异隐私, 以改进其虚拟助理和建议技术,  
    \item 在数据挖掘模型中使用差异隐私的实际表现已有一些初步研究. \citep{FLETCHER201716}
    \item 2020年LinkedIn, 用于广告客户查询
\end{itemize}
